---
title: "Replication of the Online Visual Crowding Experiment Using the Virtual Chinrest by Li et al.(2020, Scientific Reports)"
author: "Wanjing Anya Ma wanjingm@stanford.edu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

## Introduction

Online experiments enable psychophysical researchers to study larger and more diverse participant samples than they could have in the laboratory but leave challenges in controlling participants’ viewing distance and the presentation of visual stimuli. The Virtual Chinrest, introduced and validated in Li et al. (2020), was designed to tackle these challenges by an estimation of the viewing distance through measuring the participant’s blind spot location. The authors included two main parts: (1) two validation experiments of the Virtual Chinrest in the lab with participants being instructed to sit at varying viewing distances, and (2) a successful online replication of a lab-based study on visual crowding using the Virtual Chinrest. 

### Justification for choice of study

I chose to replicate this study for three reasons. (1) As a new student of psychophysical research, I am interested in learning a whole validation pipeline from a simple controlled lab environment to an uncontrolled online experiment. Due to the time constraint, I will replicate the uncontrolled online experiment (Study 4) only. (2) Replicating this study will enhance my technical skills in using jsPsych and Javascript. (3) More importantly, the second part of the study involved implementing an adaptive algorithm to present stimuli, which matches my research interest. If my schedule allows, I am interested in comparing the original findings through the staircase mode with my replication results through the bayesian adaptive mode. 

### Anticipated challenges

The major challenge I anticipate is the time constraint. Implementing an adaptive visual crowding experiment might be time-consuming if the original source code is not available. In addition, compared with the original online study that was available online for 15 months to collect data, I will not be able to replicate the whole findings in the last experiment (e.g., the difference in the viewing distance between people with and without dyslexia). 

### Links

Project repository (on Github): [AnyaWMa] https://github.com/psych251/li2020.git

Original paper (as hosted in your repo): https://github.com/psych251/li2020/blob/main/original_paper/Li_et_al-2020-Scientific_Reports.pdf

## Methods

### Power Analysis

[TO DO LATER] Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

### Planned Sample

[TO DO LATER] Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

### Experimental Design

> "The online experiment was launched on the volunteer-based online experiment platform LabintheWild and advertised with the slogan “How accurate is your peripheral vision?” on the site itself as well as on social media. Experimental design. During each experimental session, we first presented the Virtual Chinrest experiment and used the results to calculate individual’s viewing distance and to calibrate the stimuli’s size and locations. Instead of creating stimuli (demonstrated in Fig. 5) using MATLAB, we created the stimuli as SVG on HTMLs and manipulated the stimuli using JavaScript. All the elements were created in a container with a width of 900 pixels on the webpage. In the blind spot test, the dot was drawn in red with a diameter of 30 pixels, and the fixation square was drawn in black with a side length of 30 pixels (Fig. 1b). Replicating the original crowding study30 in the unit of visual degrees, stimuli comprised four flankers — open circles with 1° diameter and a target — an open circle with a gap (target; an arc with reflex central angle of 330°). All stimuli were black and displayed on a white background (Fig. 5). Two conditions of target eccentricity (the center-to-center distance between the fixation mark at the center of the webpage and the target) were 4° and 6°. In each crowding experiment session, each participant was randomly assigned one target eccentricity, and the target eccentricity was fixed with the starting target-flanker distance being set as 1.3 times greater than half the eccentricity (3.9° for 6° eccentricity; 2.6° for 4° eccentricity).
> During each crowding experiment session, the subsequent target-flanker distances (25 trials/steps in total) were controlled by the 1-up 3-down staircase procedure implemented in JavaScript [https://github.com/hadrienj/StaircaseJS]. On a given trial, the fixation mark was displayed first and remained on the webpage for the entire session. After 500 ms of fixation onset, the stimuli were displayed either to the left or the right of the fixation for 150 ms. Only the fixation remained on the webpage until the participant submitted a response by using the arrow keys on the keyboard to indicate the direction (up or down) of the target gap. No feedback was provided during the experiment. There was a 500 ms blank between a participant’s response and the beginning of the next trial. The visual crowding, defined as the minimal center-to-center distance between a target and the flankers (in degrees), was used to quantify the crowding effects when participants could report the target identity at certain accuracy. Since we are using a 1-up 3-down staircase procedure, participants should be able to correctly report the target identity 79.4% of times."

Instead of using the 1-up 3-down staircase procedure, I decided to use QUEST (Watson & Pelli, 1983) staircases to generate the target-flanker distance for each trial. This change was intended to replicate the original study of the visual crowding experiment in “Optimizing Text for an Individual’s Visual System: The Contribution of Visual Crowding to Reading Difficulties” by Joo et al. (2018, Cortex). [Joo et al. (2018, Cortex)](https://www.sciencedirect.com/science/article/pii/S0010945218300947?via%3Dihub). The specific psychometric function re-fitting rules were described below: 

> "We re-fitted the psychometric function using QUEST procedure by setting the threshold and the slope as free parameters. We excluded staircases in which threshold estimate was greater than the maximum flanker-target distance (6 or 10), which suggested that the staircase did not converge. We also excluded staircases with a threshold estimate being less than the minimum flanker-target distance (1) where the flankers and the target overlap... We averaged the threshold estimates of those remaining staircases to define each subject's critical spacing. Including staircases with threshold estimates <1 did not change the results."

### Procedure
> "The experiment began with a brief overview of the study, an informed consent form approved by the University of Washington Institutional Review Board, and a voluntary demographic questionnaire, followed by the card task and the blind spot test with 5 trials to calculate participants’ viewing distances. Participants were then presented the instruction of the crowding tasks and a practice session with 5 trials. The main experiment was split into two blocks (two independent staircases, 25 trials each), and each was followed by another blind spot task with 3 trials. After the last blind spot test, participants were then given the opportunity to report on any technical difficulties, and to provide any other general comments or questions. The final page showed their personalized “crowding effect” in comparison to others. The entire study took 10–12 minutes to complete."

### Analysis Plan

> "We deployed the online study in two stages, where we added more granular data log at the second stage, such as the percentage correctness of the experiment and the results of each individual trial. Therefore, the analysis of visual crowding effects (Fig. 7a,b) was performed on the data of 793 participants from the second stage, the results in Table 2 was based on a subset of 570 participants who have explicitly reported whether they have dyslexia and/or other related impairments, while the results of the viewing distances from the three blind (Fig. 7c–e) spot tests were reported from all 1153 participants. We checked for data normality by both the visual inspection of histograms and the Shapiro-Wilk normality tests before each analysis. We then conducted parametric (e.g. the Welch’s two sample t-test) and non-parametric (e.g. Mann-Whitney U test) analysis accordingly. In the linear mixed-effects regression models, t-tests (p-values) were calculated using Satterthwaite approximations for the degrees of freedom. The data analysis of all four experiments was performed in R, with the help of multiple packages."

### Differences from Original Study

Here are three major differences between this replication study and the original study. 

#### Sampling 
The original experiment was deployed online for 15 months and completed 1198 times, and after data exclusion, the valid data contained 793 participants. The large and diverse sample size allowed the researchers to study how different covariates (eccentricity, gender, age, and with/without dyslexia) relate to the effect visual crowding. However, due to the time and financial constraints, this current replication tested the effect of eccentricity among 20-30 year-old, neurotypical participants only. The sample size was ~60. 

#### Data Collection 
The original study recruited participants on the volunteer-based experiment platform LabintheWild, while this replication project used Prolific, a crowdsourcing platform recruit participants with pay. Using Prolific may lead to higher quality data because participants are paid and it doesn't need to rely on participants' self-report whether they have completed the study before. 

#### Adpative Algorithm
As described above, instead of using the 1-up 3-down staircase procedure, I decided to use QUEST (Watson & Pelli, 1983) staircases to generate the target-flanker distance for each trial. This change should optimize the estimation of participant's critical spacing. 

## Methods Addendum

### Actual Sample

sample size, demographics, data exclusions based on rules spelled out in analysis plan

### Differences from pre-data collection methods plan

Any differences from what was described as the original plan, or “none”.

## Results

### Data preparation

Data preparation following the analysis plan. 

I decided to follow the [data analysis using R](https://github.com/QishengLi/virtual_chinrest/blob/master/analysis/Exp_4_online_experiment_analysis.ipynb) provided by the first author. 
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan

The major inference from the original paper I wanted to justify was "The average visual crowding effects were significantly different between target eccentricity of 4° (mean = 1.61°) and 6° (mean = 2.66°)" (Figure 7a). This part of analysis would be completed through Mann-Whitney U test. 

### Exploratory analyses

Any follow-up analyses desired (not required).

*Side-by-side graph with original graph is ideal here*

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
